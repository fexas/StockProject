{"cells":[{"cell_type":"markdown","metadata":{"id":"FC2C3C0B95214FD5A0AE746F2E697971","trusted":true,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":true,"runtime":{"status":"default","execution_status":null},"scrolled":false,"notebookId":"64896c33a44b729e4419798c"},"source":"# StockProject XGboost"},{"cell_type":"markdown","metadata":{"id":"4BCAFEE76AC14E0487ECBDE0FCF08384","notebookId":"64896c33a44b729e4419798c","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":"- StockProject旨在使用股票市场过去的历史数据，对未来的股票收益率（return）进行尽可能精确的预测。  \n- 本文档使用的模型是XGboost。"},{"cell_type":"markdown","metadata":{"id":"2E22BAA740F14F6BAD67076805AF98F5","notebookId":"64896c33a44b729e4419798c","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":"# Package"},{"cell_type":"markdown","metadata":{"id":"4FCF51256FEE43CC85B01F5B72B8341A","notebookId":"64896c33a44b729e4419798c","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":"sklearn仅允许在cpu上训练，且该包相对古老，为了提升sklearn运行速度，我们采取如下办法："},{"cell_type":"code","metadata":{"id":"038950DC20A54252850B3BFAC58FFAF7","notebookId":"64896c33a44b729e4419798c","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"#sklearn 加速\n!pip install scikit-learn scikit-learn-intelex -i https://pypi.douban.com/simple/\nfrom sklearnex import patch_sklearn, unpatch_sklearn\npatch_sklearn()","outputs":[{"output_type":"stream","name":"stderr","text":"Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"}],"execution_count":2},{"cell_type":"code","metadata":{"id":"A1EFC18635734D6BBCED0DE3179BC343","trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"scrolled":false,"notebookId":"64896c33a44b729e4419798c"},"source":"#数据读取\nimport os\nimport pyarrow.feather as feather\n\n#数据处理\nimport pandas as pd\nimport numpy as np\n\n#进程展示\nfrom tqdm import tqdm\n\n#sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\n\n#xgboost\nimport xgboost as xgb\nfrom xgboost import XGBRegressor\n\n#超参调整\nimport optuna\n\n#存贮模型\nimport pickle\n\n#作图\nimport matplotlib.pyplot as plt ","outputs":[],"execution_count":3},{"cell_type":"markdown","metadata":{"id":"841F63227F0742EE857E3BCF7F617A0F","notebookId":"64896c33a44b729e4419798c","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":"# 数据预处理"},{"cell_type":"markdown","metadata":{"id":"8E525EEAE215422096902B8C35B39183","notebookId":"64896c33a44b729e4419798c","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":" 导入处理后的WRDS股票数据`/home/mw/input/stock3636/chars60_rank_imputed.feather`，并进行简单的数据预处理：  \n -  通过滞后一期，让当期的变量中包含需预测的变量（下一期的回报率）  \n -  删除分类变量（通过emedding和label encoder发现收效甚微）"},{"cell_type":"code","metadata":{"id":"D7FC5D4398464FDC93355BCD6E7D4F20","notebookId":"64896c33a44b729e4419798c","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"#导入数据\nwith open('/home/mw/input/stock3636/chars60_rank_imputed.feather', 'rb') as f:\n    data = feather.read_feather(f)\ndata['date'] = data['date'].astype('datetime64')\n\n\n# 滞后代码\n#我们的预测变量为下一期的股票收益率，需将下一期的股票收益率挪至本期\ndata['year_month'] = pd.to_datetime(data['date']).dt.to_period('M')\ndata['ret_fut'] = data.groupby('permno')['ret'].shift(-1)\ndata = data.dropna(axis=0,subset=['ret_fut']) #删除有空缺值的行\n\ndata.set_index('date', inplace=True)\n\n# 缺失值处理\n## 查看缺失值--没有缺失值\nprint('Missing data: {} items\\n'.format(len(data[data.isna().any(1)])), data[data.isna().any(1)]) # 看一下缺失值是哪些行\n\n#删除多多余的变量\n\n#删除分类变量--embedding后约等于没有作用且速度慢\ns = (data.dtypes == 'int64')\nobject_cols = list(s[s].index)# 移除含有类别变量的列\n# 移除数据集含有类别变量的列\ndata = data.drop(object_cols, axis=1)\n\n#删除影响数据分析的变量\ndata = data.drop(['rank_mom36m','rank_mom60m','exchcd','shrcd','lag_me','log_me'],axis=1)","outputs":[],"execution_count":1},{"cell_type":"markdown","metadata":{"id":"4A1E01BF1945457C89CDAAAF41AA261F","notebookId":"64896c33a44b729e4419798c","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":"# 模型 XGboost"},{"cell_type":"markdown","metadata":{"id":"F9BC3255FEE441AE88B6D6162230B6B0","notebookId":"64896c33a44b729e4419798c","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":"定义了类`Factor_models` ，该类旨在实现预测股票收益率并计使用样本外R方评估模型：  \n\n$R_{OOS}^2 =  1 - \\frac{\\sum_{it} (ret_{it} -\\hat{ret}^2_{it}) }{\\sum_{it} ret_{it}^2}$  \n\n这里$\\hat{ret}_{it}$代表模型预测的第$i$只股票在$t$时期的收益率（return）  \n\n- 在类的初始化方法 `__init__` 中，需要传入股票数据 `data`、初始训练时期长度 `train_period `和训练集扩展的频率 `freq`（默认为按月）。该方法用于对类的参数进行初始化。  \n\n- `predict_ret` 方法用于预测股票收益率。其根据数据的时间索引确定训练和测试日期，并**逐月拆分训练集和测试集**。然后，对训练数据进行标准化处理，使用`XGboost`对训练集进行拟合，并预测测试集的收益率。同时，每**12个月调整一次超参**，使用**训练集的最后两个月作为超参调整中的验证集**。预测结果和真实值被存储在一个数据帧中，并在每个训练结束日期打印样本外预测的R2指标。最后，将R2指标保存为CSV文件，并返回包含预测结果的数据帧。  \n```\n #超参数搜索空间                                                        \nparams = {  \n\t 'n_estimators':trial.suggest_int('n_estimators',1,1000),  \n\t'max_depth':trial.suggest_int('max_depth',1,2),  \n\t'learning_rate':trial.suggest_float('learning_rate',0.01,0.1)  \n }                                \n```\n\n- `cal_oos` 方法用于计算样本外的R2指标。它首先检查是否已经运行过 `predict_ret` 方法，如果是，则直接使用已有的预测结果数据帧，否则先调用` predict_ret` 方法进行预测。然后，根据预测结果计算样本外的R2指标，并绘制不同模型的样本外R2柱状图。最后，返回包含不同模型样本外R2指标的数据系列。  \n- 模型存储在地址`/home/mw/project/recording/Xgboostdata.pkl`"},{"cell_type":"code","metadata":{"id":"A11C88F1D81945959D6C05AA7E7458B2","notebookId":"64896c33a44b729e4419798c","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"class Factor_models(object):\n\n    def __init__(self,data,train_period,freq='m'):\n      \n       #参数初始化\n        self.data = data\n        self.train_period = train_period #初始训练时期长度\n        self.freq = freq                 #训练集expanding的频率，是按月还是按年还是其他\n        \n    def predict_ret(self):\n        dates = self.data.index.unique()\n        dates = dates.sort_values()\n        print(\"=====dates=======\")\n        print(dates)\n        test_dates= dates[self.train_period:len(dates)]\n        print(\"====test months=====\")\n        print(test_dates)\n        \n        # 创建一个train_end_list，训练集每月expanding。\n        preddf = pd.DataFrame() # 存储不同模型预测出来的y值，即存储样本外预测收益率的值\n        #记录R方\n        R2df = pd.DataFrame() # 存储不同模型预测出来的y值，即存储样本外预测收益率的值\n        #记录超参变化\n        best_hp = pd.DataFrame()\n\n        #xgboost参数初始化\n        best_params = {\n                      'n_estimators': 10,\n                      'max_depth': 2,\n                      'learning_rate': 0.01,\n                      'colsample_bytree': 0.3,\n                      'subsample': 0.1,\n                      'reg_alpha':  1,\n                      'reg_lambda': 0, \n                      'random_state': 42\n                      }\n        \n        index = 0  # 计数用\n        tuning_index = 0 #调参记数用 \n        for end_date in tqdm(test_dates,desc='Spilt and Train'): # 通过逐月改变训练集end_date的方法，切割样本\n            \n            #训练用数据\n            train_temp = self.data[self.data.index <  end_date]\n            test_temp = self.data[self.data.index == end_date]\n            \n            #测试集\n            y_test = test_temp.ret_fut\n            X_test = test_temp.drop(['ret_fut','ret','year_month'], axis=1)\n\n            #预测训练数据集\n            y_ptrain = train_temp.ret_fut\n            X_ptrain = train_temp.drop(['ret_fut','ret','year_month'], axis=1)\n            \n            #对数据进行逐列标准化\n            s = (X_ptrain.dtypes == 'float64')\n            object_cols = list(s[s].index)\n\n            scaler = StandardScaler()\n            for col in object_cols:\n                scaler.fit(X_test[col].values.reshape(-1,1))\n                X_test[col] = scaler.transform(X_test[col].values.reshape(-1,1))\n                scaler.fit(X_ptrain[col].values.reshape(-1,1))\n                X_ptrain[col] = scaler.transform(X_ptrain[col].values.reshape(-1,1))\n    \n            # 建模预测收益率\n            ## 先创建一个临时的temp_preddf,用来存储当前月份的验证集下的real y和不同模型的预测y\n            temp_preddf = pd.DataFrame() # 创建当前训练集下训练出的predict y和real y\n            y_test_rec = y_test.values.reshape(-1,1) #转为numpy\n            temp_preddf['real_y'] = y_test_rec[:,0]# real_y就是验证集valid_y的第一列。因为valid_y是真实收益率数据在vailid_date上的切割\n         \n            \"\"\"\n            超参调整\n            \"\"\" \n\n            if index == 0 or index % 12 == 11:\n\n                #tuning使用数据集\n                end_del2 = end_date - np.timedelta64(2+tuning_index,'M')\n                print('原日期：', end_date)\n                print('向前推两个月后的日期：', end_del2)\n                temp = self.data[(self.data.index <  end_del2)]\n                valid_temp = self.data[ (self.data.index >= end_del2) & (self.data.index < end_date) ]\n                if tuning_index < 4:\n                    tuning_index += 1\n\n                #训练集\n                y_train = temp.ret_fut\n                X_train = temp.drop(['ret_fut','ret','year_month'], axis=1)\n    \n\n                # 验证集\n                y_valid = valid_temp.ret_fut\n                X_valid = valid_temp.drop(['ret_fut','ret','year_month'], axis=1)\n                \n                #数据标准化\n                scaler = StandardScaler()\n                for col in object_cols:\n                    scaler.fit(X_train[col].values.reshape(-1,1))\n                    X_train[col] = scaler.fit_transform(X_train[col].values.reshape(-1,1))\n                    scaler.fit(X_valid[col].values.reshape(-1,1))\n                    X_valid[col] = scaler.fit_transform(X_valid[col].values.reshape(-1,1))\n    \n\n\n                # 定义optuna使用的目标\n            \n               # 定义目标函数\n                def objective(trial):\n                    # 设置超参数搜索空间\n                                                           \n                    params = {\n                                'n_estimators':trial.suggest_int('n_estimators',1,1000),\n                                'max_depth':trial.suggest_int('max_depth',1,2),\n                                'learning_rate':trial.suggest_float('learning_rate',0.01,0.1)\n                             }                                \n\n                    # 构建 XGBoost 模型\n                    model = xgb.XGBRegressor(**params)\n\n                    # 训练模型\n                    model.fit(X_train, y_train)\n\n                    # 在测试集上评估模型\n                    y_pred = model.predict(X_valid)\n                    mse = mean_squared_error(y_valid, y_pred)\n                    return mse\n\n                # 创建 Optuna 优化器\n                study = optuna.create_study(direction='minimize')\n\n                # 运行优化器\n                study.optimize(objective, n_trials=100)\n\n                # 最优参数\n                best_params = study.best_params\n\n                #将最优超参数记录到数据帧中\n                best_hp = best_hp.append(study.best_trial.params, ignore_index=True)\n\n                    \n\n            \n            # XGboost模型及训练\n            model = XGBRegressor(**best_params)\n\n            #训练模型\n            model.fit(X_ptrain, y_ptrain)\n            y_predict = model.predict(X_test)\n            \n             ## 将temp_preddf并入preddf\n            temp_preddf['XGboost_y'] = y_predict\n            preddf = preddf.append(temp_preddf) # 将当前valid_date下得到的predict_y和real_y一起并入preddf中\n            self._preddf = preddf\n            \n            #R2\n            denominator = (preddf['real_y'] ** 2).sum() # 分母是真实收益率的平方和\n            numerator = preddf.apply(lambda x: preddf['real_y'] - x).iloc[:,1:] # 分子是real_y - predict_y的平方和\n            numerator = (numerator ** 2).sum()\n            R2 = 1 - numerator / denominator # 再用 1 减去分子/分母\n            print(\"==================\")\n            print(\"date\",end_date)\n            print(\"Out-of-sample predicting R2:\",R2)\n            print(\"==================\")\n            R2df = R2df.append(R2,ignore_index=True )\n            \n            ## 将temp_preddf并入preddf\n            preddf = preddf.append(temp_preddf) # 将当前valid_date下得到的predict_y和real_y一起并入preddf中\n            self._preddf = preddf\n            index += 1\n\n        # 将数据帧保存为 CSV 文件\n        best_hp.to_csv('/home/mw/project/recording/best_params_XGboostdata.csv', index=False)\n        R2df.to_csv('/home/mw/project/recording/R2_XGBoostdata.csv', index=False)\n        \n        #保存模型\n        # 将模型保存到磁盘\n        with open('/home/mw/project/recording/Xgboostdata.pkl', 'wb') as f:\n            pickle.dump(model, f)\n        \n        return preddf # 最后我们只返回preddf，也就是所有期的predict y和real y\n    \n    def cal_oos(self):\n        # 计算out-of-sample R2 根据代码开头的公式\n        try:\n            preddf = self._preddf # 如果self已经有self._preddf，即self.predict_ret()已经运行过了，已经预测过收益率了，则无需再次运行。\n        except:\n            preddf = self.predict_ret() # 如果之前没有运行过self.predict_ret()，则需要运行。\n        denominator = (preddf['real_y'] ** 2).sum() # 分母是真实收益率的平方和\n        numerator = preddf.apply(lambda x: preddf['real_y'] - x).iloc[:,1:] # 分子是real_y - predict_y的平方和\n        numerator = (numerator ** 2).sum()\n        \n        roos = 1 - numerator / denominator # 再用 1 减去分子/分母\n        roos.index = roos.index.str.rstrip('_y') # 之前的index都是模型_y，比如\"OLS_y\"，不美观，删除_y。\n        fig,ax = plt.subplots(figsize = (16,12)) # 画图，将不同模型的Roos画出来。\n        plt.title('Out-of-sample predicting R2', fontsize = 20)\n        ax.bar(x = roos.index, height = roos)\n        plt.show()\n        return roos # 返回样本外Roos，这个Roos是不同模型对应的样本外R2","outputs":[],"execution_count":5},{"cell_type":"markdown","metadata":{"id":"97B2BFB6E190442892E5BC0F841821B8","notebookId":"64896c33a44b729e4419798c","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":"# 预测"},{"cell_type":"code","metadata":{"id":"1E766FE9334C432D84B36BA5EC3C4FD5","notebookId":"64896c33a44b729e4419798c","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"basic_2_factors = Factor_models(data,32,freq='m') #2013年只有8个月的数据","outputs":[],"execution_count":6},{"cell_type":"code","metadata":{"id":"74C5B988B8A74D8091582349263C2B1C","notebookId":"64896c33a44b729e4419798c","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 计算样本外R2，运行耗时较长\nroos = basic_2_factors.cal_oos() # 计算不同模型样本外R2。self.cal_oos()中已经包含了self.predict_ret()的操作，先通过不同的模型预测收益率，再比较样本外真实收益率和预测收益率的差异\nroos.to_csv('/home/mw/project/XGboostdata_tuning_roos.csv')","outputs":[],"execution_count":2}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":0}