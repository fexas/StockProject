{"cells":[{"cell_type":"markdown","metadata":{"id":"22041AF3B2364460BB7FED5C00B8DCA5","trusted":true,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":true,"runtime":{"status":"default","execution_status":null},"scrolled":false,"notebookId":"64896d07a44b729e44197e8a"},"source":"#  StockProject RF  (RandomForest)  \n"},{"cell_type":"markdown","metadata":{"id":"EE5D38309ECC4078A60E7759D90A9D36","notebookId":"64896d07a44b729e44197e8a","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":"- StockProject旨在使用股票市场过去的历史数据，对未来的股票收益率（return）进行尽可能精确的预测。  \n- 本文档使用的模型是RF。"},{"cell_type":"markdown","metadata":{"id":"ECD7A7C84FCF4FCE9D5183E06DFA1684","notebookId":"64896d07a44b729e44197e8a","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":"# Package"},{"cell_type":"markdown","metadata":{"id":"97B373B815564A318305B0AC4C304B22","notebookId":"64896d07a44b729e44197e8a","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":"sklearn仅允许在cpu上训练，且该包相对古老，为了提升sklearn运行速度，我们采取如下办法："},{"cell_type":"code","metadata":{"id":"D3946E5262EB4A06BA81DB8DDDCA147A","trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"scrolled":true,"notebookId":"64896d07a44b729e44197e8a"},"source":"#sklearn 加速\n!pip install scikit-learn scikit-learn-intelex -i https://pypi.douban.com/simple/\nfrom sklearnex import patch_sklearn, unpatch_sklearn\npatch_sklearn()","outputs":[{"output_type":"stream","name":"stderr","text":"Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"}],"execution_count":2},{"cell_type":"code","metadata":{"id":"052F4670E4C54995995D42B27468B448","notebookId":"64896d07a44b729e44197e8a","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"#数据读取\nimport os\nimport pyarrow.feather as feather\n\n#数据处理\nimport pandas as pd\nimport numpy as np\n\n#sklearn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor\n\n#进程展示\nfrom tqdm import tqdm\n\n#超参调整\nimport optuna\n\n#存贮模型\nimport pickle\n\n#作图\nimport matplotlib.pyplot as plt ","outputs":[],"execution_count":3},{"cell_type":"markdown","metadata":{"id":"0EF5087F7480466BBFA6310017544D0E","notebookId":"64896d07a44b729e44197e8a","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":"# 数据预处理"},{"cell_type":"markdown","metadata":{"id":"F5EC5EE499E14B6589879ED3F0D2E3D5","notebookId":"64896d07a44b729e44197e8a","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":" 导入处理后的WRDS股票数据`/home/mw/input/stock3636/chars60_rank_imputed.feather`，并进行简单的数据预处理：  \n -  通过滞后一期，让当期的变量中包含需预测的变量（下一期的回报率）  \n -  删除分类变量（通过emedding和label encoder发现收效甚微）"},{"cell_type":"code","metadata":{"id":"1F84CBCE48994E88BDB31AB1C50513CF","notebookId":"64896d07a44b729e44197e8a","jupyter":{},"collapsed":false,"scrolled":true,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"#导入数据\nwith open('/home/mw/input/stock3636/chars60_rank_imputed.feather', 'rb') as f:\n    data = feather.read_feather(f)\ndata['date'] = data['date'].astype('datetime64')\n\n\n# 滞后代码\n#我们的预测变量为下一期的股票收益率，需将下一期的股票收益率挪至本期\ndata['year_month'] = pd.to_datetime(data['date']).dt.to_period('M')\ndata['ret_fut'] = data.groupby('permno')['ret'].shift(-1)\ndata = data.dropna(axis=0,subset=['ret_fut']) #删除有空缺值的行\n\ndata.set_index('date', inplace=True)\n\n# 缺失值处理\n## 查看缺失值--没有缺失值\nprint('Missing data: {} items\\n'.format(len(data[data.isna().any(1)])), data[data.isna().any(1)]) # 看一下缺失值是哪些行\n\n#删除多多余的变量\n#删除分类变量--embedding后约等于没有作用且速度慢\ns = (data.dtypes == 'int64')\nobject_cols = list(s[s].index)# 移除含有类别变量的列\n# 移除数据集含有类别变量的列\ndata = data.drop(['gvkey', 'permno', 'sic'], axis=1)\n\n#删除影响数据分析的变量\ndata = data.drop(['rank_mom36m','rank_mom60m','exchcd','shrcd','lag_me','log_me'],axis=1)","outputs":[],"execution_count":1},{"cell_type":"markdown","metadata":{"id":"E1E9721CE3D047ADA966A0513D49B9AA","notebookId":"64896d07a44b729e44197e8a","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":"# 模型 RandomForest"},{"cell_type":"markdown","metadata":{"id":"287C6D1834FF4E5EB81CB55FAA827614","notebookId":"64896d07a44b729e44197e8a","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":"封装随机森林回归模型，实现训练`train`、预测`predict`和评估`evaluate`操作。  \n\n初始化`init`接受三个可选参数：  \n- `n_estimators`: 决策树的数量，默认为300  \n- `max_depth`: 决策树的最大深度，默认为None，表示不限制深度  \n- `max_features`: 每棵决策树的最大特征数量，默认为50）"},{"cell_type":"code","metadata":{"id":"8A90406061164425BD4BCBA551C182FB","notebookId":"64896d07a44b729e44197e8a","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"class RandomForest:\n    def __init__(self, n_estimators=300, max_depth=None, max_features=50):\n        self.n_estimators = n_estimators\n        self.max_depth = max_depth\n        self.max_features = max_features\n        self.model = RandomForestRegressor(n_estimators=self.n_estimators, max_depth=self.max_depth, max_features=self.max_features)\n    \n    def train(self, X, y):\n        self.model.fit(X, y)\n    \n    def predict(self, X):\n        return self.model.predict(X)\n    \n    def evaluate(self, X, y):\n        y_pred = self.predict(X)\n        mse = mean_squared_error(y, y_pred)\n        rmse = np.sqrt(mse)\n        return rmse","outputs":[],"execution_count":5},{"cell_type":"markdown","metadata":{"id":"8EC374F7B30B4E1F90951D9671F2C526","notebookId":"64896d07a44b729e44197e8a","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":"定义了类`Factor_models` ，该类旨在实现预测股票收益率并计使用样本外R方评估模型：  \n\n$R_{OOS}^2 =  1 - \\frac{\\sum_{it} (ret_{it} -\\hat{ret}^2_{it}) }{\\sum_{it} ret_{it}^2}$  \n\n这里$\\hat{ret}_{it}$代表模型预测的第$i$只股票在$t$时期的收益率（return）  \n\n- 在类的初始化方法 `__init__` 中，需要传入股票数据 `data`、初始训练时期长度 `train_period `和训练集扩展的频率 `freq`（默认为按月）。该方法用于对类的参数进行初始化。  \n\n- `predict_ret` 方法用于预测股票收益率。其根据数据的时间索引确定训练和测试日期，并**逐月拆分训练集和测试集**。然后，对训练数据进行标准化处理，使用`RandomForest`对训练集进行拟合，并预测测试集的收益率。同时，每**12个月调整一次超参**，使用训练集的最后两个月作为超参调整中的验证集。预测结果和真实值被存储在一个数据帧中，并在每个训练结束日期打印样本外预测的R2指标。最后，将R2指标保存为CSV文件，并返回包含预测结果的数据帧。  \n```\n# 定义超参数搜索空间  \nmax_depth = trial.suggest_int(\"max_depth\", 1, 6)  \nn_estimators = 300  \nmax_features = trial.suggest_categorical(\"max_features\", [3, 5, 10, 20, 30, 50])  \n```\n\n- `cal_oos` 方法用于计算样本外的R2指标。它首先检查是否已经运行过 `predict_ret` 方法，如果是，则直接使用已有的预测结果数据帧，否则先调用` predict_ret` 方法进行预测。然后，根据预测结果计算样本外的R2指标，并绘制不同模型的样本外R2柱状图。最后，返回包含不同模型样本外R2指标的数据系列。"},{"cell_type":"code","metadata":{"id":"F30D14B2EC9749ECA185828E0F8ABF8B","notebookId":"64896d07a44b729e44197e8a","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"class Factor_models(object):\n\n    def __init__(self,data,train_period,freq='m'):\n      \n       #参数初始化\n        self.data = data\n        self.train_period = train_period #初始训练时期长度\n        self.freq = freq                 #训练集expanding的频率，是按月还是按年还是其他\n        \n    def predict_ret(self):\n        dates = self.data.index.unique()\n        dates = dates.sort_values()\n        print(\"=====dates=======\")\n        print(dates)\n        test_dates= dates[self.train_period:len(dates)]\n        print(\"====test months=====\")\n        print(test_dates)\n        \n        # 创建一个train_end_list，训练集每月expanding。\n        preddf = pd.DataFrame() # 存储不同模型预测出来的y值，即存储样本外预测收益率的值\n        #记录R方\n        R2df = pd.DataFrame() # 存储不同模型预测出来的y值，即存储样本外预测收益率的值\n        #记录超参变化\n        best_hp = pd.DataFrame()\n        \n        index = 0  # 计数用\n        for end_date in tqdm(test_dates,desc='Spilt and Train'): # 通过逐月改变训练集end_date的方法，切割样本\n            \n            #训练用数据\n            train_temp = self.data[self.data.index <  end_date]\n            test_temp = self.data[self.data.index == end_date]\n            \n            #测试集\n            y_test = test_temp.ret_fut\n            X_test = test_temp.drop(['ret_fut','ret','year_month'], axis=1)\n\n            #预测训练数据集\n            y_ptrain = train_temp.ret_fut\n            X_ptrain = train_temp.drop(['ret_fut','ret','year_month'], axis=1)\n            \n            #对数据进行逐列标准化\n            s = (X_ptrain.dtypes == 'float64')\n            object_cols = list(s[s].index)\n\n            scaler = StandardScaler()\n            for col in object_cols:\n                scaler.fit(X_test[col].values.reshape(-1,1))\n                X_test[col] = scaler.transform(X_test[col].values.reshape(-1,1))\n                scaler.fit(X_ptrain[col].values.reshape(-1,1))\n                X_ptrain[col] = scaler.transform(X_ptrain[col].values.reshape(-1,1))\n    \n            # 建模预测收益率\n            ## 先创建一个临时的temp_preddf,用来存储当前月份的验证集下的real y和不同模型的预测y\n            temp_preddf = pd.DataFrame() # 创建当前训练集下训练出的predict y和real y\n            y_test_rec = y_test.values.reshape(-1,1) #转为numpy\n            temp_preddf['real_y'] = y_test_rec[:,0]# real_y就是验证集valid_y的第一列。因为valid_y是真实收益率数据在vailid_date上的切割\n         \n            \"\"\"\n            超参调整\n            \"\"\" \n\n            if index == 0 or index % 12 == 11:\n\n                #tuning使用数据集\n                end_del2 = end_date - np.timedelta64(2,'M')\n                temp = self.data[(self.data.index <  end_del2)]\n                valid_temp = self.data[ (self.data.index >= end_del2) & (self.data.index < end_date) ]\n\n\n                #训练集\n                y_train = temp.ret_fut\n                X_train = temp.drop(['ret_fut','ret','year_month'], axis=1)\n    \n\n                # 验证集\n                y_valid = valid_temp.ret_fut\n                X_valid = valid_temp.drop(['ret_fut','ret','year_month'], axis=1)\n                \n                #数据标准化\n                scaler = StandardScaler()\n                for col in object_cols:\n                    scaler.fit(X_train[col].values.reshape(-1,1))\n                    X_train[col] = scaler.fit_transform(X_train[col].values.reshape(-1,1))\n                    scaler.fit(X_valid[col].values.reshape(-1,1))\n                    X_valid[col] = scaler.fit_transform(X_valid[col].values.reshape(-1,1))\n    \n\n\n                # 定义optuna使用的目标\n            \n               # 定义目标函数\n                def objective(trial):\n                    # 设置超参数搜索空间\n                    \n                     # 定义超参数搜索空间\n                    max_depth = trial.suggest_int(\"max_depth\", 1, 6)\n                    n_estimators = 300\n                    max_features = trial.suggest_categorical(\"max_features\", [3, 5, 10, 20, 30, 50])\n\n                    # 训练模型\n                    rf = RandomForest(n_estimators = 300, max_depth=max_depth, max_features=max_features)\n                    rf.train(X_train, y_train)\n                \n    \n                    # 在验证集上评估模型\n                    rmse = rf.evaluate(X_valid, y_valid)\n                    return rmse\n\n                # 创建 Optuna 优化器\n                study = optuna.create_study(direction='minimize')\n\n                # 运行优化器\n                study.optimize(objective, n_trials=100)\n\n                # 最优参数\n                best_params = study.best_params\n                # 输出最优超参数组合和测试集上的准确率\n                print('Best hyperparameters:', study.best_params)\n\n                #将最优超参数记录到数据帧中\n                best_hp = best_hp.append(study.best_trial.params, ignore_index=True)\n                               \n            # RandomForest模型及训练\n            rf = RandomForest(n_estimators = 300,max_depth=best_params['max_depth'], max_features =best_params['max_features'])\n\n            # 在整个训练集上重新训练模型\n            rf.train(X_ptrain, y_ptrain)\n            y_predict = rf.predict(X_test)\n            \n            # 将temp_preddf并入preddf\n            temp_preddf['RandomForest_y'] = y_predict\n            preddf = preddf.append(temp_preddf) # 将当前valid_date下得到的predict_y和real_y一起并入preddf中\n            self._preddf = preddf\n            \n            #R2\n            denominator = (preddf['real_y'] ** 2).sum() # 分母是真实收益率的平方和\n            numerator = preddf.apply(lambda x: preddf['real_y'] - x).iloc[:,1:] # 分子是real_y - predict_y的平方和\n            numerator = (numerator ** 2).sum()\n            R2 = 1 - numerator / denominator # 再用 1 减去分子/分母\n            print(\"==================\")\n            print(\"index:\",index)\n            print(\"Out-of-sample predicting R2:\",R2)\n            print(\"==================\")\n            R2df = R2df.append(R2,ignore_index=True )\n            \n            ## 将temp_preddf并入preddf\n            preddf = preddf.append(temp_preddf) # 将当前valid_date下得到的predict_y和real_y一起并入preddf中\n            self._preddf = preddf\n            index += 1\n\n        # 将数据帧保存为 CSV 文件\n        best_hp.to_csv('/home/mw/project/recording/best_params_rfg_data.csv', index=False)\n        R2df.to_csv('/home/mw/project/recording/R2_rfg_data.csv', index=False)\n        \n        #保存模型\n        # 将模型保存到磁盘\n        with open('/home/mw/project/recording/RandomForest_given_data.pkl', 'wb') as f:\n            pickle.dump(rf, f)\n        \n        return preddf # 最后我们只返回preddf，也就是所有期的predict y和real y\n    \n    def cal_oos(self):\n        # 计算out-of-sample R2 根据代码开头的公式\n        try:\n            preddf = self._preddf # 如果self已经有self._preddf，即self.predict_ret()已经运行过了，已经预测过收益率了，则无需再次运行。\n        except:\n            preddf = self.predict_ret() # 如果之前没有运行过self.predict_ret()，则需要运行。\n        denominator = (preddf['real_y'] ** 2).sum() # 分母是真实收益率的平方和\n        numerator = preddf.apply(lambda x: preddf['real_y'] - x).iloc[:,1:] # 分子是real_y - predict_y的平方和\n        numerator = (numerator ** 2).sum()\n        \n        roos = 1 - numerator / denominator # 再用 1 减去分子/分母\n        roos.index = roos.index.str.rstrip('_y') # 之前的index都是模型_y，比如\"OLS_y\"，不美观，删除_y。\n        fig,ax = plt.subplots(figsize = (16,12)) # 画图，将不同模型的Roos画出来。\n        plt.title('Out-of-sample predicting R2', fontsize = 20)\n        ax.bar(x = roos.index, height = roos)\n        plt.show()\n        return roos # 返回样本外Roos，这个Roos是不同模型对应的样本外R2","outputs":[],"execution_count":6},{"cell_type":"markdown","metadata":{"id":"D05AB41D42E54015A354B087ED1657FA","notebookId":"64896d07a44b729e44197e8a","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":"# 预测"},{"cell_type":"code","metadata":{"id":"DD28DDD269A94B578C53C3830FA8D793","notebookId":"64896d07a44b729e44197e8a","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"basic_2_factors = Factor_models(data,32,freq='m') #2013年只有八年的数据","outputs":[],"execution_count":7},{"cell_type":"code","metadata":{"id":"00B41542DF1544D18CDE6AC4B0F817C0","notebookId":"64896d07a44b729e44197e8a","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 计算样本外R2，运行耗时较长\nroos = basic_2_factors.cal_oos() # 计算不同模型样本外R2。self.cal_oos()中已经包含了self.predict_ret()的操作，先通过不同的模型预测收益率，再比较样本外真实收益率和预测收益率的差异\nroos.to_csv('/home/mw/project/rfg_data_tuning_roos.csv')","outputs":[],"execution_count":1}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":0}