{"cells":[{"cell_type":"markdown","metadata":{"id":"0159628312A445A59B737D6B5F9FBEB4","trusted":true,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":true,"runtime":{"status":"default","execution_status":null},"scrolled":false,"notebookId":"64897a46a44b729e441a1136"},"source":"# StockProject PCA + LightGBM"},{"cell_type":"markdown","metadata":{"id":"5EC29831A25C49F28A8921CD7CA71651","notebookId":"64897a46a44b729e441a1136","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":"- StockProject旨在使用股票市场过去的历史数据，对未来的股票收益率（return）进行尽可能精确的预测。  \n- 本文档使用的模型是PCA+LightGBM。  \n\n加入PCA的原因：  \n- 去除数据噪声和共线性问题，以提高模型的表现  \n- 数据降维可以提高运行速度"},{"cell_type":"markdown","metadata":{"id":"5B7F8C3E6A7840CC865F5213C8604F19","notebookId":"64897a46a44b729e441a1136","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":"# Package"},{"cell_type":"markdown","metadata":{"id":"3C11EE2774BB4A91887E0203447A45C9","notebookId":"64897a46a44b729e441a1136","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":"sklearn仅允许在cpu上训练，且该包相对古老，为了提升sklearn运行速度，我们采取如下办法："},{"cell_type":"code","metadata":{"id":"4ACD2B6B19A24FB88E4ACA46C9DC26E6","notebookId":"64897a46a44b729e441a1136","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"#sklearn 加速\n!pip install scikit-learn scikit-learn-intelex -i https://pypi.douban.com/simple/\nfrom sklearnex import patch_sklearn, unpatch_sklearn\npatch_sklearn()","outputs":[{"output_type":"stream","name":"stderr","text":"Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"}],"execution_count":47},{"cell_type":"code","metadata":{"id":"14865AD1B43C4B928AD230713E00948D","trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"scrolled":false,"notebookId":"64897a46a44b729e441a1136"},"source":"#数据读取\nimport os\nimport pyarrow.feather as feather\n\n#数据处理\nimport numpy as np\nimport pandas as pd\n\n#进程展示\nfrom tqdm import tqdm\n\n#sklearn-pca\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\n\n#lgbm\nimport lightgbm as lgb\n\n#超参调优\nimport optuna\n\n#存贮模型\nimport pickle\n\n#作图\nimport matplotlib.pyplot as plt ","outputs":[],"execution_count":48},{"cell_type":"markdown","metadata":{"id":"2B30A47A6050490EA3BAF120B588C16A","notebookId":"64897a46a44b729e441a1136","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":"# 数据预处理"},{"cell_type":"markdown","metadata":{"id":"07C9AD40C0C941A585251DC76AE1866D","notebookId":"64897a46a44b729e441a1136","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":" 导入处理后的WRDS股票数据`/home/mw/input/stock3636/chars60_rank_imputed.feather`，并进行简单的数据预处理：  \n -  通过滞后一期，让当期的变量中包含需预测的变量（下一期的回报率）  \n -  删除分类变量（通过emedding和label encoder发现收效甚微）"},{"cell_type":"code","metadata":{"id":"ECBCE608AE7F4103850A17193BFBAD69","notebookId":"64897a46a44b729e441a1136","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"#导入数据\nwith open('/home/mw/input/stock3636/chars60_rank_imputed.feather', 'rb') as f:\n    data = feather.read_feather(f)\ndata['date'] = data['date'].astype('datetime64')\n\n\n# 滞后代码\n#我们的预测变量为下一期的股票收益率，需将下一期的股票收益率挪至本期\ndata['year_month'] = pd.to_datetime(data['date']).dt.to_period('M')\ndata['ret_fut'] = data.groupby('permno')['ret'].shift(-1)\ndata = data.dropna(axis=0,subset=['ret_fut']) #删除有空缺值的行\n\ndata.set_index('date', inplace=True)\n\n# 缺失值处理\n## 查看缺失值--没有缺失值\nprint('Missing data: {} items\\n'.format(len(data[data.isna().any(1)])), data[data.isna().any(1)]) # 看一下缺失值是哪些行\n\n#删除多多余的变量\n\n#删除分类变量--embedding后约等于没有作用且速度慢\ns = (data.dtypes == 'int64')\nobject_cols = list(s[s].index)# 移除含有类别变量的列\n# 移除数据集含有类别变量的列\ndata = data.drop(object_cols, axis=1)\n\n#删除影响数据分析的变量\ndata = data.drop(['rank_mom36m','rank_mom60m','exchcd','shrcd','lag_me','log_me'],axis=1)","outputs":[],"execution_count":1},{"cell_type":"markdown","metadata":{"id":"D8E489C51C9C4F01A90D17872A61B611","notebookId":"64897a46a44b729e441a1136","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":"# 模型 PCA+LightGBM"},{"cell_type":"markdown","metadata":{"id":"3971CB4027764D989ED7F2EDF68EA184","notebookId":"64897a46a44b729e441a1136","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":"定义了类`Factor_models` ，该类旨在实现预测股票收益率并计使用样本外R方评估模型：  \n\n$R_{OOS}^2 =  1 - \\frac{\\sum_{it} (ret_{it} -\\hat{ret}^2_{it}) }{\\sum_{it} ret_{it}^2}$  \n\n这里$\\hat{ret}_{it}$代表模型预测的第$i$只股票在$t$时期的收益率（return）  \n\n- 在类的初始化方法 `__init__` 中，需要传入股票数据 `data`、初始训练时期长度 `train_period `和训练集扩展的频率 `freq`（默认为按月）。该方法用于对类的参数进行初始化。  \n\n- `predict_ret` 方法用于预测股票收益率。其根据数据的时间索引确定训练和测试日期，并**逐月拆分训练集和测试集**。然后，对训练数据进行标准化处理和`PCA`降维，使用`lgbm`对训练集进行拟合，并预测测试集的收益率。同时，每**12个月调整一次超参**，使用**训练集的最后两个月作为超参调整中的验证集**。预测结果和真实值被存储在一个数据帧中，并在每个训练结束日期打印样本外预测的R2指标。最后，将R2指标保存为CSV文件，并返回包含预测结果的数据帧。  \n```\n #超参数搜索空间                                                        \nparams = {  \n\t'objective': 'regression',  \n\t'metric': 'rmse',  \n\t'verbosity': -1,  \n\t'boosting_type': 'gbdt',  \n\t'num_leaves': trial.suggest_int('num_leaves', 10, 100),  \n\t'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1,log=True),  \n\t'min_child_samples': trial.suggest_int('min_child_samples', 1, 50),  \n\t'max_depth': trial.suggest_int('max_depth', 1, 2),  \n\t'subsample': trial.suggest_float('subsample', 0.1, 1),  \n\t'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1),  \n\t'n_estimators': trial.suggest_int('n_estimators', 50, 500),  \n}                              \n```\n\n- `cal_oos` 方法用于计算样本外的R2指标。它首先检查是否已经运行过 `predict_ret` 方法，如果是，则直接使用已有的预测结果数据帧，否则先调用` predict_ret` 方法进行预测。然后，根据预测结果计算样本外的R2指标，并绘制不同模型的样本外R2柱状图。最后，返回包含不同模型样本外R2指标的数据系列。  \n-  模型存储在地址`/home/mw/project/recording/lightgbM_data.pkl`"},{"cell_type":"code","metadata":{"id":"2D2BB627738344FF8BC8D45C70EEB129","notebookId":"64897a46a44b729e441a1136","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"class Factor_models(object):\n\n    def __init__(self,data,train_period,freq='m'):\n      \n       #参数初始化\n        self.data = data\n        self.train_period = train_period #初始训练时期长度\n        self.freq = freq                 #训练集expanding的频率，是按月还是按年还是其他\n        \n    def predict_ret(self):\n        dates = self.data.index.unique()\n        dates = dates.sort_values()\n        print(\"=====dates=======\")\n        print(dates)\n        test_dates= dates[self.train_period:len(dates)]\n        print(\"====test months=====\")\n        print(test_dates)\n        \n        # 创建一个train_end_list，训练集每月expanding。\n        preddf = pd.DataFrame() # 存储不同模型预测出来的y值，即存储样本外预测收益率的值\n        #记录R方\n        R2df = pd.DataFrame() # 存储不同模型预测出来的y值，即存储样本外预测收益率的值\n        #记录超参变化\n        best_hp = pd.DataFrame()\n        \n        index = 0  # 计数用\n        tuning_index = 0 #调参记数用 \n        for end_date in tqdm(test_dates,desc='Spilt and Train'): # 通过逐月改变训练集end_date的方法，切割样本\n            \n            #训练用数据\n            train_temp = self.data[self.data.index <  end_date]\n            test_temp = self.data[self.data.index == end_date]\n            \n            #测试集\n            y_test = test_temp.ret_fut\n            X_test = test_temp.drop(['ret_fut','ret','year_month'], axis=1)\n\n            #预测训练数据集\n            y_ptrain = train_temp.ret_fut\n            X_ptrain = train_temp.drop(['ret_fut','ret','year_month'], axis=1)\n            \n            #对数据进行逐列标准化\n            s = (X_ptrain.dtypes == 'float64')\n            object_cols = list(s[s].index)\n\n            scaler = StandardScaler()\n            for col in object_cols:\n                scaler.fit(X_test[col].values.reshape(-1,1))\n                X_test[col] = scaler.transform(X_test[col].values.reshape(-1,1))\n                scaler.fit(X_ptrain[col].values.reshape(-1,1))\n                X_ptrain[col] = scaler.transform(X_ptrain[col].values.reshape(-1,1))\n\n            \n    \n            # 建模预测收益率\n            ## 先创建一个临时的temp_preddf,用来存储当前月份的验证集下的real y和不同模型的预测y\n            temp_preddf = pd.DataFrame() # 创建当前训练集下训练出的predict y和real y\n            y_test_rec = y_test.values.reshape(-1,1) #转为numpy\n            temp_preddf['real_y'] = y_test_rec[:,0]# real_y就是验证集valid_y的第一列。因为valid_y是真实收益率数据在vailid_date上的切割\n            \n\n            #PCA降维\n            pca = PCA(n_components='mle',svd_solver='full') # 根据PCR模型预测收益率\n            pca.fit(X_ptrain)\n            X_ptrain_pca = pca.transform(X_ptrain)\n            X_test_pca = pca.transform(X_test)\n\n            \"\"\"\n            超参调整\n            \"\"\" \n\n            if index == 0 or index % 12 == 11:\n\n                #tuning使用数据集\n                end_del2 = end_date - np.timedelta64(2,'M')\n                print('原日期：', end_date)\n                print('向前推两个月后的日期：', end_del2)\n                temp = self.data[(self.data.index <  end_del2)]\n                valid_temp = self.data[ (self.data.index >= end_del2) & (self.data.index < end_date) ]\n\n\n                #训练集\n                y_train = temp.ret_fut\n                X_train = temp.drop(['ret_fut','ret','year_month'], axis=1)\n    \n\n                # 验证集\n                y_valid = valid_temp.ret_fut\n                X_valid = valid_temp.drop(['ret_fut','ret','year_month'], axis=1)\n                \n                #数据标准化\n                scaler = StandardScaler()\n                for col in object_cols:\n                    scaler.fit(X_train[col].values.reshape(-1,1))\n                    X_train[col] = scaler.fit_transform(X_train[col].values.reshape(-1,1))\n                    scaler.fit(X_valid[col].values.reshape(-1,1))\n                    X_valid[col] = scaler.fit_transform(X_valid[col].values.reshape(-1,1))\n    \n\n                X_train_pca = pca.transform(X_train)\n                X_valid_pca = pca.transform(X_valid)\n                # 定义optuna使用的目标\n            \n               # 定义目标函数\n                # 定义目标函数\n                def objective(trial):\n    \n                    # 定义参数空间\n                    params = {\n                                'objective': 'regression',\n                                'metric': 'rmse',\n                                'verbosity': -1,\n                                'boosting_type': 'gbdt',\n                                'num_leaves': trial.suggest_int('num_leaves', 10, 100),\n                                'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1,log=True),\n                                'min_child_samples': trial.suggest_int('min_child_samples', 1, 50),\n                                'max_depth': trial.suggest_int('max_depth', 1, 2),\n                                'subsample': trial.suggest_float('subsample', 0.1, 1),\n                                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1),\n                                'n_estimators': trial.suggest_int('n_estimators', 50, 500)\n                             }\n    \n                    # 训练模型\n                    model = lgb.LGBMRegressor(**params)\n                    model.fit(X_train_pca, y_train)\n    \n                    # 在测试集上进行预测\n                    y_pred = model.predict(X_test_pca)\n    \n                    # 计算 RMSE\n                    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    \n                    return rmse\n\n                # 创建 Optuna 优化器\n                study = optuna.create_study(direction='minimize')\n\n                # 运行优化器\n                study.optimize(objective, n_trials=100)\n\n                # 最优参数\n                best_params = study.best_params\n\n                #将最优超参数记录到数据帧中\n                best_hp = best_hp.append(study.best_trial.params, ignore_index=True)\n\n                    \n\n            \n            # pca+lgbm模型及训练\n            model = lgb.LGBMRegressor(**best_params)\n\n            #训练模型\n            model.fit(X_ptrain_pca, y_ptrain)\n            y_predict = model.predict(X_test_pca)\n            \n             ## 将temp_preddf并入preddf\n            temp_preddf['lightgbm_y'] = y_predict\n            preddf = preddf.append(temp_preddf) # 将当前valid_date下得到的predict_y和real_y一起并入preddf中\n            self._preddf = preddf\n            \n            #R2\n            denominator = (preddf['real_y'] ** 2).sum() # 分母是真实收益率的平方和\n            numerator = preddf.apply(lambda x: preddf['real_y'] - x).iloc[:,1:] # 分子是real_y - predict_y的平方和\n            numerator = (numerator ** 2).sum()\n            R2 = 1 - numerator / denominator # 再用 1 减去分子/分母\n            print(\"==================\")\n            print(\"date\",end_date)\n            print(\"Out-of-sample predicting R2:\",R2)\n            print(\"==================\")\n            R2df = R2df.append(R2,ignore_index=True )\n            \n            ## 将temp_preddf并入preddf\n            preddf = preddf.append(temp_preddf) # 将当前valid_date下得到的predict_y和real_y一起并入preddf中\n            self._preddf = preddf\n            index += 1\n\n        # 将数据帧保存为 CSV 文件\n        best_hp.to_csv('/home/mw/project/recording/best_params_lgbm_data.csv', index=False)\n        R2df.to_csv('/home/mw/project/recording/R2_lgbm_data.csv', index=False)\n        \n        #保存模型\n        with open('/home/mw/project/recording/lightgbM_data.pkl', 'wb') as f:\n            pickle.dump(model, f)\n        \n        return preddf # 最后我们只返回preddf，也就是所有期的predict y和real y\n    \n    def cal_oos(self):\n        # 计算out-of-sample R2 根据代码开头的公式\n        try:\n            preddf = self._preddf # 如果self已经有self._preddf，即self.predict_ret()已经运行过了，已经预测过收益率了，则无需再次运行。\n        except:\n            preddf = self.predict_ret() # 如果之前没有运行过self.predict_ret()，则需要运行。\n        denominator = (preddf['real_y'] ** 2).sum() # 分母是真实收益率的平方和\n        numerator = preddf.apply(lambda x: preddf['real_y'] - x).iloc[:,1:] # 分子是real_y - predict_y的平方和\n        numerator = (numerator ** 2).sum()\n        \n        roos = 1 - numerator / denominator # 再用 1 减去分子/分母\n        roos.index = roos.index.str.rstrip('_y') # 之前的index都是模型_y，比如\"OLS_y\"，不美观，删除_y。\n        fig,ax = plt.subplots(figsize = (16,12)) # 画图，将不同模型的Roos画出来。\n        plt.title('Out-of-sample predicting R2', fontsize = 20)\n        ax.bar(x = roos.index, height = roos)\n        plt.show()\n        return roos # 返回样本外Roos，这个Roos是不同模型对应的样本外R2","outputs":[],"execution_count":50},{"cell_type":"markdown","metadata":{"id":"099A65DDB4004F7F9B95AD57890D7B7E","notebookId":"64897a46a44b729e441a1136","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":"# 预测"},{"cell_type":"code","metadata":{"id":"5DE355ED4A1E42F7A4CE018BCB56B913","notebookId":"64897a46a44b729e441a1136","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"basic_2_factors = Factor_models(data,32,freq='m') #2013年只有8个月的数据","outputs":[],"execution_count":51},{"cell_type":"code","metadata":{"id":"4ACF03482D9344CDA3A3DF2A2DC9E09F","notebookId":"64897a46a44b729e441a1136","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 计算样本外R2，运行耗时较长\nroos = basic_2_factors.cal_oos() # 计算不同模型样本外R2。self.cal_oos()中已经包含了self.predict_ret()的操作，先通过不同的模型预测收益率，再比较样本外真实收益率和预测收益率的差异\nroos.to_csv('/home/mw/project/pca_lgbm_data_tuning_roos.csv')","outputs":[],"execution_count":2}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":0}