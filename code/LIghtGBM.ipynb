{"cells":[{"cell_type":"markdown","metadata":{"id":"74E75217C2D74F29BF5702F2D947FD3E","jupyter":{},"mdEditEnable":true,"notebookId":"6489bbb4a44b729e441ac9b4","papermill":{"duration":0.028634,"end_time":"2023-06-14T08:33:33.990806","exception":false,"start_time":"2023-06-14T08:33:33.962172","status":"completed"},"runtime":{"status":"default","execution_status":null},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":"# StockProject LightGBM"},{"cell_type":"markdown","metadata":{"id":"1F52F204911445E58C6D55F000D94A98","notebookId":"6489bbb4a44b729e441ac9b4","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":"- StockProject旨在使用股票市场过去的历史数据，对未来的股票收益率（return）进行尽可能精确的预测。  \n- 本文档使用的模型是LightGBM。"},{"cell_type":"markdown","metadata":{"id":"5CFDA1116E8A4B8CAA255D9E63F23FDA","jupyter":{},"notebookId":"6489bbb4a44b729e441ac9b4","papermill":{"duration":0.024451,"end_time":"2023-06-14T08:33:34.042627","exception":false,"start_time":"2023-06-14T08:33:34.018176","status":"completed"},"runtime":{"status":"default","execution_status":null},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":"# Package"},{"cell_type":"code","metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2023-06-14T08:33:38.590593Z","iopub.status.busy":"2023-06-14T08:33:38.590406Z","iopub.status.idle":"2023-06-14T08:33:39.711776Z","shell.execute_reply":"2023-06-14T08:33:39.711005Z"},"id":"8318BA9BDA6248DEAD8ADC275FBB4B6B","jupyter":{"source_hidden":true},"notebookId":"6489bbb4a44b729e441ac9b4","papermill":{"duration":1.166144,"end_time":"2023-06-14T08:33:39.715331","exception":false,"start_time":"2023-06-14T08:33:38.549187","status":"completed"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"#数据读取\nimport os\nimport pyarrow.feather as feather\n\n#数据处理\nimport numpy as np\nimport pandas as pd\n\n#进程展示\nfrom tqdm import tqdm\n\n#sklearn\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\n\n#lgbm\nimport lightgbm as lgb\n\n#超参调优\nimport optuna\n\n#存贮模型\nimport pickle\n\n#作图\nimport matplotlib.pyplot as plt ","outputs":[],"execution_count":20},{"cell_type":"markdown","metadata":{"id":"B5E729AFE540458EAA3CC2C29332B239","jupyter":{},"notebookId":"6489bbb4a44b729e441ac9b4","papermill":{"duration":0.031006,"end_time":"2023-06-14T08:33:39.799024","exception":false,"start_time":"2023-06-14T08:33:39.768018","status":"completed"},"runtime":{"status":"default","execution_status":null},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":"# 数据预处理"},{"cell_type":"markdown","metadata":{"id":"026632B5E5A547CE82127E221C2C8F41","notebookId":"6489bbb4a44b729e441ac9b4","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":" 导入处理后的WRDS股票数据`/home/mw/input/stock3636/chars60_rank_imputed.feather`，并进行简单的数据预处理：  \n -  通过滞后一期，让当期的变量中包含需预测的变量（下一期的回报率）  \n -  删除分类变量（通过emedding和label encoder发现收效甚微）"},{"cell_type":"code","metadata":{"id":"5E94BA48D88640189CA223ECB4AFF788","notebookId":"6489bbb4a44b729e441ac9b4","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 设置全局随机种子，以保证结果可复现\nnp.random.seed(42)","outputs":[],"execution_count":21},{"cell_type":"code","metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2023-06-14T08:33:39.854835Z","iopub.status.busy":"2023-06-14T08:33:39.854326Z","iopub.status.idle":"2023-06-14T08:33:41.353555Z","shell.execute_reply":"2023-06-14T08:33:41.352865Z"},"id":"5967BEABCBFC4E6592CA99D9D8525329","jupyter":{"source_hidden":true},"notebookId":"6489bbb4a44b729e441ac9b4","papermill":{"duration":1.531013,"end_time":"2023-06-14T08:33:41.357723","exception":false,"start_time":"2023-06-14T08:33:39.826710","status":"completed"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"#导入数据\nwith open('/home/mw/input/stock3636/chars60_rank_imputed.feather', 'rb') as f:\n    data = feather.read_feather(f)\ndata['date'] = data['date'].astype('datetime64')\n\n\n# 滞后代码\ndata['year_month'] = pd.to_datetime(data['date']).dt.to_period('M')\ndata['ret_fut'] = data.groupby('permno')['ret'].shift(-1)\ndata = data.dropna(axis=0,subset=['ret_fut']) #删除有空缺值的行\n\ndata.set_index('date', inplace=True)\n\n# 缺失值处理\n## 查看缺失值--没有缺失值\nprint('Missing data: {} items\\n'.format(len(data[data.isna().any(1)])), data[data.isna().any(1)]) # 看一下缺失值是哪些行\n\n#删除多多余的变量\n\n#删除分类变量--embedding后约等于没有作用且速度慢\ns = (data.dtypes == 'int64')\nobject_cols = list(s[s].index)# 移除含有类别变量的列\n# 移除数据集含有类别变量的列\ndata = data.drop(object_cols, axis=1)\n\n#删除影响数据分析的变量\ndata = data.drop(['rank_mom36m','rank_mom60m','exchcd','shrcd','lag_me','log_me'],axis=1)","outputs":[],"execution_count":1},{"cell_type":"markdown","metadata":{"id":"FB93BD56D2ED4C3084D57EE16ED6891A","jupyter":{},"notebookId":"6489bbb4a44b729e441ac9b4","papermill":{"duration":0.03453,"end_time":"2023-06-14T08:33:41.436047","exception":false,"start_time":"2023-06-14T08:33:41.401517","status":"completed"},"runtime":{"status":"default","execution_status":null},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":"# 模型 LightGBM"},{"cell_type":"markdown","metadata":{"id":"F7B86336A9534AC883E516FD4D3EAF1A","notebookId":"6489bbb4a44b729e441ac9b4","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":"定义了类`Factor_models` ，该类旨在实现预测股票收益率并计使用样本外R方评估模型：  \n\n$R_{OOS}^2 =  1 - \\frac{\\sum_{it} (ret_{it} -\\hat{ret}^2_{it}) }{\\sum_{it} ret_{it}^2}$  \n\n这里$\\hat{ret}_{it}$代表模型预测的第$i$只股票在$t$时期的收益率（return）  \n\n- 在类的初始化方法 `__init__` 中，需要传入股票数据 `data`、初始训练时期长度 `train_period `和训练集扩展的频率 `freq`（默认为按月）。该方法用于对类的参数进行初始化。  \n\n- `predict_ret` 方法用于预测股票收益率。其根据数据的时间索引确定训练和测试日期，并**逐月拆分训练集和测试集**。然后，对训练数据进行标准化处理，使用`lgbm`对训练集进行拟合，并预测测试集的收益率。同时，每**12个月调整一次超参**，使用**训练集的最后两个月作为超参调整中的验证集**。预测结果和真实值被存储在一个数据帧中，并在每个训练结束日期打印样本外预测的R2指标。最后，将R2指标保存为CSV文件，并返回包含预测结果的数据帧。  \n```\n #超参数搜索空间                                                        \nparams = {  \n\t'objective': 'regression',  \n\t'metric': 'rmse',  \n\t'verbosity': -1,  \n\t'boosting_type': 'gbdt',  \n\t'num_leaves': trial.suggest_int('num_leaves', 10, 100),  \n\t'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1,log=True),  \n\t'min_child_samples': trial.suggest_int('min_child_samples', 1, 50),  \n\t'max_depth': trial.suggest_int('max_depth', 1, 2),  \n\t'subsample': trial.suggest_float('subsample', 0.1, 1),  \n\t'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1),  \n\t'n_estimators': trial.suggest_int('n_estimators', 50, 500),  \n}                              \n```\n\n- `cal_oos` 方法用于计算样本外的R2指标。它首先检查是否已经运行过 `predict_ret` 方法，如果是，则直接使用已有的预测结果数据帧，否则先调用` predict_ret` 方法进行预测。然后，根据预测结果计算样本外的R2指标，并绘制不同模型的样本外R2柱状图。最后，返回包含不同模型样本外R2指标的数据系列。  \n- 模型存储在地址`/home/mw/project/lightgbm.pkl`"},{"cell_type":"code","metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2023-06-14T08:33:41.500513Z","iopub.status.busy":"2023-06-14T08:33:41.500045Z","iopub.status.idle":"2023-06-14T08:33:41.558788Z","shell.execute_reply":"2023-06-14T08:33:41.557865Z"},"id":"7D06428453F44728B4963A28BC433ACE","jupyter":{"source_hidden":true},"notebookId":"6489bbb4a44b729e441ac9b4","papermill":{"duration":0.094735,"end_time":"2023-06-14T08:33:41.561946","exception":false,"start_time":"2023-06-14T08:33:41.467211","status":"completed"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"class Factor_models(object):\n\n    def __init__(self,data,train_period,freq='m'):\n      \n       #参数初始化\n        self.data = data\n        self.train_period = train_period #初始训练时期长度\n        self.freq = freq                 #训练集expanding的频率，是按月还是按年还是其他\n        \n    def predict_ret(self):\n        dates = self.data.index.unique()\n        dates = dates.sort_values()\n        print(\"=====dates=======\")\n        print(dates)\n        test_dates= dates[self.train_period:len(dates)]\n        print(\"====test months=====\")\n        print(test_dates)\n        \n        # 创建一个train_end_list，训练集每月expanding。\n        preddf = pd.DataFrame() # 存储不同模型预测出来的y值，即存储样本外预测收益率的值\n        #记录R方\n        R2df = pd.DataFrame() # 存储不同模型预测出来的y值，即存储样本外预测收益率的值\n        #记录超参变化\n        best_hp = pd.DataFrame()\n        \n        index = 0  # 计数用\n        tuning_index = 0 #调参记数用 \n        for end_date in tqdm(test_dates,desc='Spilt and Train'): # 通过逐月改变训练集end_date的方法，切割样本\n            \n            #训练用数据\n            train_temp = self.data[self.data.index <  end_date]\n            test_temp = self.data[self.data.index == end_date]\n            \n            #测试集\n            y_test = test_temp.ret_fut\n            X_test = test_temp.drop(['ret_fut','year_month'], axis=1)\n\n            #预测训练数据集\n            y_ptrain = train_temp.ret_fut\n            X_ptrain = train_temp.drop(['ret_fut','year_month'], axis=1)\n            \n            #对数据进行逐列标准化\n            s = (X_ptrain.dtypes == 'float64')\n            object_cols = list(s[s].index)\n\n            scaler = StandardScaler()\n            for col in object_cols:\n                scaler.fit(X_test[col].values.reshape(-1,1))\n                X_test[col] = scaler.transform(X_test[col].values.reshape(-1,1))\n                scaler.fit(X_ptrain[col].values.reshape(-1,1))\n                X_ptrain[col] = scaler.transform(X_ptrain[col].values.reshape(-1,1))\n\n            \n    \n            # 建模预测收益率\n            ## 先创建一个临时的temp_preddf,用来存储当前月份的验证集下的real y和不同模型的预测y\n            temp_preddf = pd.DataFrame() # 创建当前训练集下训练出的predict y和real y\n            y_test_rec = y_test.values.reshape(-1,1) #转为numpy\n            temp_preddf['real_y'] = y_test_rec[:,0]# real_y就是验证集valid_y的第一列。因为valid_y是真实收益率数据在vailid_date上的切割\n            \n\n            \"\"\"\n            超参调整\n            \"\"\" \n\n            if ((index == 0 or index % 12 == 11) and index < 82):\n\n                #tuning使用数据集\n                end_del2 = end_date - np.timedelta64(2,'M')\n                print('原日期：', end_date)\n                print('向前推两个月后的日期：', end_del2)\n                temp = self.data[(self.data.index <  end_del2)]\n                valid_temp = self.data[ (self.data.index >= end_del2) & (self.data.index < end_date) ]\n\n\n                #训练集\n                y_train = temp.ret_fut\n                X_train = temp.drop(['ret_fut','year_month'], axis=1)\n    \n\n                # 验证集\n                y_valid = valid_temp.ret_fut\n                X_valid = valid_temp.drop(['ret_fut','year_month'], axis=1)\n                \n                #数据标准化\n                scaler = StandardScaler()\n                for col in object_cols:\n                    scaler.fit(X_train[col].values.reshape(-1,1))\n                    X_train[col] = scaler.fit_transform(X_train[col].values.reshape(-1,1))\n                    scaler.fit(X_valid[col].values.reshape(-1,1))\n                    X_valid[col] = scaler.fit_transform(X_valid[col].values.reshape(-1,1))\n    \n\n                # 定义optuna使用的目标\n            \n               # 定义目标函数\n                # 定义目标函数\n                def objective(trial):\n    \n                    # 定义参数空间\n                    params = {\n                                'objective': 'regression',\n                                'metric': 'rmse',\n                                'verbosity': -1,\n                                'boosting_type': 'gbdt',\n                                'num_leaves': trial.suggest_int('num_leaves', 10, 100),\n                                'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1,log=True),\n                                'min_child_samples': trial.suggest_int('min_child_samples', 1, 50),\n                                'max_depth': trial.suggest_int('max_depth', 1, 2),\n                                'subsample': trial.suggest_float('subsample', 0.1, 1),\n                                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1),\n                                'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n                             }\n    \n                    # 训练模型\n                    model = lgb.LGBMRegressor(**params)\n                    model.fit(X_train, y_train)\n    \n                    # 在测试集上进行预测\n                    y_pred = model.predict(X_valid)\n    \n                    # 计算 RMSE\n                    rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n    \n                    return rmse\n\n                # 创建 Optuna 优化器\n                study = optuna.create_study(direction='minimize')\n\n                # 运行优化器\n                study.optimize(objective, n_trials=100)\n\n                # 最优参数\n                best_params = study.best_params\n\n                #将最优超参数记录到数据帧中\n                best_hp = best_hp.append(study.best_trial.params, ignore_index=True)\n          \n            # Lightgbm模型及训练\n            model = lgb.LGBMRegressor(**best_params)\n\n            #训练模型\n            model.fit(X_ptrain, y_ptrain)\n            y_predict = model.predict(X_test)\n            \n             ## 将temp_preddf并入preddf\n            temp_preddf['lightgbm_y'] = y_predict\n            preddf = preddf.append(temp_preddf) # 将当前valid_date下得到的predict_y和real_y一起并入preddf中\n            self._preddf = preddf\n            \n            #R2\n            denominator = (preddf['real_y'] ** 2).sum() # 分母是真实收益率的平方和\n            numerator = preddf.apply(lambda x: preddf['real_y'] - x).iloc[:,1:] # 分子是real_y - predict_y的平方和\n            numerator = (numerator ** 2).sum()\n            R2 = 1 - numerator / denominator # 再用 1 减去分子/分母\n            print(\"==================\")\n            print(\"date\",end_date)\n            print(\"Out-of-sample predicting R2:\",R2)\n            print(\"==================\")\n            R2df = R2df.append(R2,ignore_index=True )\n            \n            ## 将temp_preddf并入preddf\n            preddf = preddf.append(temp_preddf) # 将当前valid_date下得到的predict_y和real_y一起并入preddf中\n            self._preddf = preddf\n            index += 1\n\n        # 将数据帧保存为 CSV 文件\n        best_hp.to_csv('/home/mw/project/best_params_lgbm.csv', index=False)\n        R2df.to_csv('/home/mw/project/R2_lgbm.csv', index=False)\n        \n        #保存模型\n        with open('/home/mw/project/lightgbm.pkl', 'wb') as f:\n            pickle.dump(model, f)\n        \n        return preddf # 最后我们只返回preddf，也就是所有期的predict y和real y\n    \n    def cal_oos(self):\n        # 计算out-of-sample R2 根据代码开头的公式\n        try:\n            preddf = self._preddf # 如果self已经有self._preddf，即self.predict_ret()已经运行过了，已经预测过收益率了，则无需再次运行。\n        except:\n            preddf = self.predict_ret() # 如果之前没有运行过self.predict_ret()，则需要运行。\n        denominator = (preddf['real_y'] ** 2).sum() # 分母是真实收益率的平方和\n        numerator = preddf.apply(lambda x: preddf['real_y'] - x).iloc[:,1:] # 分子是real_y - predict_y的平方和\n        numerator = (numerator ** 2).sum()\n        \n        roos = 1 - numerator / denominator # 再用 1 减去分子/分母\n        roos.index = roos.index.str.rstrip('_y') # 之前的index都是模型_y，比如\"OLS_y\"，不美观，删除_y。\n        return roos # 返回样本外Roos，这个Roos是不同模型对应的样本外R2","outputs":[],"execution_count":23},{"cell_type":"markdown","metadata":{"id":"9E56677BDA7D403F98F4FEA4B676B490","jupyter":{},"notebookId":"6489bbb4a44b729e441ac9b4","papermill":{"duration":0.03116,"end_time":"2023-06-14T08:33:41.629444","exception":false,"start_time":"2023-06-14T08:33:41.598284","status":"completed"},"runtime":{"status":"default","execution_status":null},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":"# 预测"},{"cell_type":"code","metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2023-06-14T08:33:41.690383Z","iopub.status.busy":"2023-06-14T08:33:41.689954Z","iopub.status.idle":"2023-06-14T08:33:41.696258Z","shell.execute_reply":"2023-06-14T08:33:41.695150Z"},"id":"E0F7904A773A4C97879AA16E10D058A7","jupyter":{"source_hidden":true},"notebookId":"6489bbb4a44b729e441ac9b4","papermill":{"duration":0.040368,"end_time":"2023-06-14T08:33:41.698487","exception":false,"start_time":"2023-06-14T08:33:41.658119","status":"completed"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"basic_2_factors = Factor_models(data,32,freq='m') #2013年只有8个月的数据","outputs":[],"execution_count":24},{"cell_type":"code","metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2023-06-14T08:33:41.747585Z","iopub.status.busy":"2023-06-14T08:33:41.747168Z","iopub.status.idle":"2023-06-14T10:03:31.404477Z","shell.execute_reply":"2023-06-14T10:03:31.403313Z"},"id":"9D0E40028B05421FAE36330FEC85C312","jupyter":{"source_hidden":true},"notebookId":"6489bbb4a44b729e441ac9b4","papermill":{"duration":5389.68718,"end_time":"2023-06-14T10:03:31.410185","exception":false,"start_time":"2023-06-14T08:33:41.723005","status":"completed"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"# 计算样本外R2，运行耗时较长\nroos = basic_2_factors.cal_oos() # 计算不同模型样本外R2。self.cal_oos()中已经包含了self.predict_ret()的操作，先通过不同的模型预测收益率，再比较样本外真实收益率和预测收益率的差异\nroos.to_csv('/home/mw/project/lgbm_tuning_roos.csv')","outputs":[],"execution_count":2}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":5}